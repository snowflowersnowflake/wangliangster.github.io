## 矩阵
机器学习中，其数据都可以用一个矩阵来表示， 一般的对于一个$m\times n$矩阵， 习惯性的用$m$表示样本数量，$n$表示单个样本的特征(属性)数量，即有$n$维特征的$m$个样本。

由此可窥，矩阵之于机器学习的重要性。以下是有关它的一些基本运算关系记录。
### 转置
$$
(A')'=A \\
(A+B)'=A'+B'\\
(AB)'=B'A'\\
(kA)'=kA'
$$

### 逆
设$A_{ij}$是矩阵
$$
A=\left [ \begin{array}{c} a_{11} & a_{12} & ...& a_{1n} \\
a_{21} & a_{22} & ...& a_{2n} \\
... & ... & ...& ... \\
a_{n1} & a_{n2} & ...& a_{nn} \\
\end{array} \right]
$$
中元素$a_{ij}$的代数余子式，令
$$
A^{\bullet}=
\left [ \begin{array}{c} A_{11} & A_{12} & ...& A_{1n} \\
A_{21} & A_{22} & ...& A_{2n} \\
... & ... & ...& ... \\
A_{n1} & A_{n2} & ...& A_{nn} \\
\end{array} \right]
$$
则称
$$
A^{\bigstar}=(A^{\bullet})'=
\left [ \begin{array}{c} A_{11} & A_{21} & ...& A_{n1} \\
A_{12} & A_{22} & ...& A_{n2} \\
... & ... & ...& ... \\
A_{1n} & A_{2n} & ...& A_{nn} \\
\end{array} \right]
$$
为矩阵$A$的**伴随矩阵**，若$d=|A| \nLeftrightarrow 0$，则$A$的**逆**为:
$$
A^{-1}=\frac{1}{d}A^{\bigstar}
$$
由此也可知，矩阵可逆的充要条件是其行列式值$|A| \nLeftrightarrow 0$

上面求逆方法运算量巨大，但给出了漂亮的**通用数学表达式**，一般情况对于方阵还有如下求逆方法：

- <font color=blue> 作一$n\times 2n$矩阵$(A,E)$，用初等**行变换**把它左边的一半化成$E$，这时右边的一半就是$A^{-1}$ </font>

当然现在的数学软件中大多都有API可直接调用，其内部实现算法也是基于基本原理的实现的。


## 广义逆

**定义:** 
$A$是$m\times n$矩阵，若$n\times m$矩阵$G$满足
$$
AGA=A
$$
则称$G$为$A$的一个**广义逆矩阵**，简称**广义逆**

**定理:**
 设$AX=b$有解，且$b\nLeftrightarrow 0$,则称它的解的一般形式为$Gb$，其中$G$为$A$的任意一个广义逆。

由上可知**广义逆**并不唯一。

#### Moore-Penrose 广义逆
**定义:**
$A$是**复**$m\times n$矩阵，若$n\times m$矩阵$G$满足：
- $AGA=A$
- $GAG=G$
- $(\overline{AG})'=AG$
- $(\overline{GA})'=GA$
则称$G$为$A$的**Moore-Penrose 广义逆**

**定理:**
对于任意$A$,它的Moore-Penrose 广义逆永远存在，且**唯一**
