## 矩阵
机器学习中，其数据都可以用一个矩阵来表示， 一般的对于一个$m\times n$矩阵， 习惯性的用$m$表示样本数量，$n$表示单个样本的特征(属性)数量，即有$n$维特征的$m$个样本。

由此可窥，矩阵之于机器学习的重要性。以下是有关它的一些基本运算关系记录。
### 转置
$$
(A')'=A \\
(A+B)'=A'+B'\\
(AB)'=B'A'\\
(kA)'=kA'
$$

### 逆
设$A_{ij}$是矩阵
$$
A=\left [ \begin{array}{c} a_{11} & a_{12} & ...& a_{1n} \\
a_{21} & a_{22} & ...& a_{2n} \\
... & ... & ...& ... \\
a_{n1} & a_{n2} & ...& a_{nn} \\
\end{array} \right]
$$
中元素$a_{ij}$的代数余子式，令
$$
A^{\bullet}=
\left [ \begin{array}{c} A_{11} & A_{12} & ...& A_{1n} \\
A_{21} & A_{22} & ...& A_{2n} \\
... & ... & ...& ... \\
A_{n1} & A_{n2} & ...& A_{nn} \\
\end{array} \right]
$$
则称
$$
A^{\bigstar}=(A^{\bullet})'=
\left [ \begin{array}{c} A_{11} & A_{21} & ...& A_{n1} \\
A_{12} & A_{22} & ...& A_{n2} \\
... & ... & ...& ... \\
A_{1n} & A_{2n} & ...& A_{nn} \\
\end{array} \right]
$$
为矩阵$A$的**伴随矩阵**，若$d=|A| \nLeftrightarrow 0$，则$A$的**逆**为:
$$
A^{-1}=\frac{1}{d}A^{\bigstar}
$$
由此也可知，矩阵可逆的充要条件是其行列式值$|A| \nLeftrightarrow 0$

上面求逆方法运算量巨大，但给出了漂亮的**通用数学表达式**，一般情况对于方阵还有如下求逆方法：

- <font color=blue> 作一$n\times 2n$矩阵$(A,E)$，用初等**行变换**把它左边的一半化成$E$，这时右边的一半就是$A^{-1}$ </font>

当然现在的数学软件中大多都有API可直接调用，其内部实现算法也是基于基本原理的实现的。

