## Hessian 矩阵

[Jacobi矩阵](AI/ML/jacobi.md)的梯度，也就是向量值函数的二阶导数就是**Hessian矩阵**，

由微分算子二阶偏导的可交换性：
$$
\frac{\partial^2 f(x)}{\partial x_i \partial x_j}=\frac{\partial^2 f(x)}{\partial x_j \partial x_i}
$$

可知**Hessian矩阵**是实对称矩阵，即$H_{i,j}=H_{j,i}$

由单变量连续函数的二阶导数分析可知， 若$f^{''}(x)$:

- 大于零，说明变化率（一阶导数）单调递增，它的形状一般是向下凹的（二次函数下凹图）
- 等于零，说明变化率为零，函数没有**曲率**
- 小于零，说明变化率（一阶导数）单调递减，它的形状一般是上凸的（二次函数翻转$a<0$)


## 单变量一阶导与二阶导对极值的判断：
- $f'(x)=0， f''(x)>0$， 则$x$是一个局部**极小值**点
- $f'(x)=0， f''(x)<0$， 则$x$是一个局部**极大值**点
- $f'(x)=0， f''(x)=0$， 则$x$是一个**鞍点**或平坦区域的一部分

## 多维变量一阶导与二阶导对极值的判断：
- $J=0，$ 若$H$是正定的，则$x$是一个局部**极小值**点
- $J=0，$ 若$H$是负定的，则$x$是一个局部**极大值**点
- $J=0，$ 若$H$是不定的，则$x$是一个**鞍点**， 鞍点可以理解为一个方向截面取极大值，另一垂直截面取极小值，不一定要求$det(H)=0$

### H 的特征分解

因为$H$是实对称矩阵，所以它一定可以特征分解：$H=V'DV$

特征向量对应的方向的**特征值**就是该方向的二阶导数，特征值的不同说明**方向导数**并不是所有的**方向**都是一样的，**梯度**只是其中一个方向，最大特征值方向揭示了“梯度的效率方向。
